{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating unicity for 3 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation and pickling of `results` and `data_by_point` dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dict_tools import *\n",
    "import pickle #For saving dictionaries with results\n",
    "import time #For calculating timings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS\n",
    "def coarsen_time(timestamp,degree):\n",
    "    '''Coarsen time by the degree `degree`.\n",
    "    Degree is either 'd' (day), 'm' (minute), 'h' (hour), 's' (second), or False (exclude)\n",
    "    '''\n",
    "    if degree == 'd':\n",
    "        return timestamp[0:10]\n",
    "    elif degree == 'h':\n",
    "        return timestamp[0:13]\n",
    "    elif degree == 'm':\n",
    "        return timestamp[0:16]\n",
    "    elif degree == 's':\n",
    "        return timestamp[0:19]\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "unknown_curr = set()\n",
    "def coarsen_amount(amount,degree,currency):\n",
    "    '''Coarsen amount by the degree `degree`, which depends on the strength of\\\n",
    "        the `currency`. \n",
    "        `degree` can take:\n",
    "        'm'\" max, 'h': High, 'm': Medium, 'l': low\n",
    "        \n",
    "        Note that strength is not checked online, so it may not\\\n",
    "        be accurate if the strength of a currency has changed dramatically\n",
    "        \n",
    "        Note that rounding may not be perfect owing to floating point issues\n",
    "    '''\n",
    "    #Strength of currencies in 2014, I'm going to check these (I think XRP is \\\n",
    "    # now about as strong as the pound)\n",
    "    \n",
    "    strong_curr = ('BTC', 'XAG','XAU', 'XPT')\n",
    "    med_curr = ('CNY','EUR','USD','AUD','GBP','JPY') #<- STRENGTH OF XRP HAS CHANGED SINCE 2015\n",
    "    weak_curr = ('CCK','STR','KRW','MTL','XRP')\n",
    "    \n",
    "    lookup_strong = {'h': 1e-3, 'a': 1e-2, 'l': 1e-1}\n",
    "    lookup_med = {'h': 1e1, 'a': 1e2, 'l': 1e3}\n",
    "    lookup_weak = {'h': 1e5, 'a': 1e6, 'l': 1e7}\n",
    "    if degree is False:\n",
    "        return None\n",
    "    elif degree == 'm':\n",
    "        return amount\n",
    "    else:\n",
    "        if currency in strong_curr:\n",
    "            prec = lookup_strong[degree]\n",
    "        elif currency in med_curr:\n",
    "            prec = lookup_med[degree]\n",
    "        elif currency in weak_curr:\n",
    "            prec = lookup_weak[degree]\n",
    "        else:\n",
    "            unknown_curr.add(currency)\n",
    "            #print(\"Unknown currency {}\".format(currency))\n",
    "            prec = 1\n",
    "    \n",
    "        coarse_amount = float(int(round(amount/prec)))*prec\n",
    "\n",
    "        return coarse_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "start_date = datetime.date(2017,6,1)\n",
    "end_date = datetime.date(2017,8,29)\n",
    "date_list = pd.date_range(start_date,end_date,freq=\"1D\")\n",
    "\n",
    "files = []\n",
    "for day in date_list:\n",
    "    #print(\"Current date: {}\".format(day.strftime(\"%Y-%m-%d\")))\n",
    "    this_day = day.strftime(\"%Y-%m-%d\")\n",
    "    next_day = (day+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    files.append(\"Ripple_transactions_{}_to_{}.csv\".format(this_day,next_day))\n",
    "\n",
    "def load_data_by_sender(files,a_res,include_c,t_res,include_d):\n",
    "    '''Create dictionary from a list of file names `file` \\\n",
    "        with keys being senders and datapoints by tuple \\\n",
    "        (Amount, Currency, Time, Destination)'''\n",
    "    data_by_sender = {}\n",
    "    for file in tqdm(files):\n",
    "        i = 0\n",
    "        for line in csv.reader(open(file,'r')):\n",
    "            if i == 0:\n",
    "                header = line\n",
    "            else:\n",
    "                sender = line[header.index('Sender')]\n",
    "                \n",
    "                \n",
    "                curr = line[header.index('Currency')]\n",
    "                amount = coarsen_amount(float(line[header.index('Amount')]),a_res,curr)   #<- COARSENING \n",
    "                time = coarsen_time(line[header.index('Timestamp')],t_res)       #<- COARSENING\n",
    "                if include_d:\n",
    "                    destination = line[header.index('Destination')]\n",
    "                else:\n",
    "                    destination = None\n",
    "                if not include_c:\n",
    "                    curr = None\n",
    "                datapoint = tuple([amount,curr,time,destination])\n",
    "                \n",
    "                if sender not in data_by_sender:\n",
    "                    data_by_sender[sender] = set() \n",
    "                data_by_sender[sender].add(tuple(datapoint))\n",
    "            i+=1\n",
    "    return data_by_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def by_point(data_by_sender):\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping datapoints (Amount, Currency, Time, Destination) to the \\\n",
    "    users who share this datapoint\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"CONVERTING DATA BY SENDER TO DATA BY POINT\")\n",
    "    \n",
    "    data_by_point = {}\n",
    "    for sender in tqdm(data_by_sender):\n",
    "        for datapoint in data_by_sender[sender]:\n",
    "            if datapoint not in data_by_point:\n",
    "                data_by_point[datapoint] = set()\n",
    "            data_by_point[datapoint].add(sender)\n",
    "    \n",
    "    return data_by_point\n",
    "\n",
    "def get_unicity(dataset,p,npeople = 10000):\n",
    "    \"\"\"\n",
    "    Returns unicity (float) of `dataset` (dict), where `p` (int) is number of points sampled for each \\\n",
    "     person (if they have that many points) and `npeople` (int) is the number of people for whom their \\\n",
    "     uniqueness (for a set of points) is calculated\n",
    "    \"\"\"\n",
    "    if npeople == 'all':\n",
    "        npeople = len(dataset.keys())\n",
    "    else:\n",
    "        npeople = int(npeople) #Just to make sure\n",
    "    \n",
    "    points_to_users = by_point(dataset)\n",
    "    \n",
    "    print(\"User number: \",len(dataset))\n",
    "    print(\"Point number: \",len(points_to_users))\n",
    "\n",
    "    unique_users = set()\n",
    "    users = random.sample(list(dataset.keys()),npeople)\n",
    "    \n",
    "    users_included = set() #<- Users with at least p points\n",
    "\n",
    "    for u in tqdm(users):\n",
    "\n",
    "        u_data = dataset[u]\n",
    "\n",
    "        if len(u_data) < p: # <- NOT len(u_data) <= p\n",
    "            continue\n",
    "        else:\n",
    "            p_points = random.sample(u_data,p)\n",
    "            users_included.add(u)\n",
    "        is_unique = True\n",
    "        \n",
    "        similar_people = set(dataset.keys())\n",
    "\n",
    "        for point in p_points:\n",
    "            similar_people = similar_people.intersection(points_to_users[point])\n",
    "   \n",
    "\n",
    "        if len(similar_people) > 1:\n",
    "            is_unique = False\n",
    "            continue #<-NEED TO CONTINUE NOT BREAK!\n",
    "        \n",
    "        if is_unique:\n",
    "            unique_users.add(u) \n",
    "\n",
    "    print(\"Users included:\",len(users_included))\n",
    "    return len(unique_users)/len(users_included) #<-COMPARING WITH NUMBER OF USERS WITH AT LEAST p POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiments = {\"Am,Tsc,C,D\":['m',True,'s',True],\n",
    "               \"Am,Tsc,-,D\":['m',False,'s',True],\n",
    "               \"Am,Tsc,C,-\":['m',True,'s',False],\n",
    "               \"-,Tsc,C,D\": [False,True,'s',True],\n",
    "               \"Ah,Tmn,C,D\":['h',True,'m',True],\n",
    "               \"Aa,Thr,C,D\":['a',True,'h',True],\n",
    "               \"Al,Tdy,C,D\":['l',True,'d',True],\n",
    "               \"Am,-,C,D\":['m',True,False,True],\n",
    "               \"Am,-,-,-\":['m',False,False,False],\n",
    "               \"Al,Tdy,-,-\":['l',False,'d',False]\n",
    "              }\n",
    "experiments_test = {\"Am,Tsc,C,D\":['m',True,'s',True],\n",
    "               \"Am,Tsc,C,-\":['m',True,'s',False],\n",
    "               \"-,Tsc,C,D\":[False,True,'s',True],\n",
    "               }\n",
    "def run_experiment(parameters,p,name=\"unnamed_ripple_experiment\",npeople=10000):\n",
    "    '''Run experiment using resolutions defined in `parameters` \\\n",
    "        (Amount res, Include Currency, Time res, Include Destination)\n",
    "        and picking p datapoints for the unicity test\n",
    "        \n",
    "        Pickles the coarsened dataset object to a file {NAME}_p{P VALUE}-data_by_sender.pkl\n",
    "        '''\n",
    "    print(\"LOADING DATA\")\n",
    "    data_by_sender = load_data_by_sender(files,*parameters)\n",
    "    filename = '{}_p{}-data_by_sender.pkl'.format(name,p)\n",
    "    print(\"PICKLING DATA to {}\".format(filename))\n",
    "    pickle.dump(data_by_sender,open(filename,'wb'))\n",
    "    print(\"CALCULATING UNICITY\")\n",
    "    unicity = get_unicity(data_by_sender,p,npeople)\n",
    "    return unicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "EXPERIMENT Am,Tsc,C,D: COARSENING: ['m', True, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,Tsc,C,D_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2310577\n",
      "\n",
      "Users included: 4043\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,Tsc,-,D: COARSENING: ['m', False, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,Tsc,-,D_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2310571\n",
      "\n",
      "Users included: 3936\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,Tsc,C,-: COARSENING: ['m', True, 's', False]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,Tsc,C,-_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2216491\n",
      "\n",
      "Users included: 3973\n",
      "-------------------------------------------\n",
      "EXPERIMENT -,Tsc,C,D: COARSENING: [False, True, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to -,Tsc,C,D_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2219769\n",
      "\n",
      "Users included: 3962\n",
      "-------------------------------------------\n",
      "EXPERIMENT Ah,Tmn,C,D: COARSENING: ['h', True, 'm', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Ah,Tmn,C,D_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2047914\n",
      "\n",
      "Users included: 3915\n",
      "-------------------------------------------\n",
      "EXPERIMENT Aa,Thr,C,D: COARSENING: ['a', True, 'h', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Aa,Thr,C,D_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  1646653\n",
      "\n",
      "Users included: 3700\n",
      "-------------------------------------------\n",
      "EXPERIMENT Al,Tdy,C,D: COARSENING: ['l', True, 'd', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Al,Tdy,C,D_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  931636\n",
      "\n",
      "Users included: 3382\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,-,C,D: COARSENING: ['m', True, False, True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,-,C,D_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  770124\n",
      "\n",
      "Users included: 3793\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,-,-,-: COARSENING: ['m', False, False, False]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,-,-,-_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  479794\n",
      "\n",
      "Users included: 3718\n",
      "-------------------------------------------\n",
      "EXPERIMENT Al,Tdy,-,-: COARSENING: ['l', False, 'd', False]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Al,Tdy,-,-_p3-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  181818\n",
      "\n",
      "Users included: 3396\n"
     ]
    }
   ],
   "source": [
    "results_p3 = dict()\n",
    "for exp in experiments:\n",
    "    print(\"-------------------------------------------\\nEXPERIMENT {}: COARSENING: {}\".format(exp,experiments[exp]))\n",
    "    results_p3[exp] = run_experiment(experiments[exp],p=3,name=exp,npeople=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(results_p3,open('results_p3.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-,Tsc,C,D': 0.9941948510853105,\n",
       " 'Aa,Thr,C,D': 0.9964864864864865,\n",
       " 'Ah,Tmn,C,D': 0.9994891443167305,\n",
       " 'Al,Tdy,-,-': 0.40577149587750294,\n",
       " 'Al,Tdy,C,D': 0.9482554701360142,\n",
       " 'Am,-,-,-': 0.6000537923614847,\n",
       " 'Am,-,C,D': 0.9169522805167414,\n",
       " 'Am,Tsc,-,D': 1.0,\n",
       " 'Am,Tsc,C,-': 0.9997483010319658,\n",
       " 'Am,Tsc,C,D': 0.9997526589166461}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_p3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import winsound\n",
    "winsound.MessageBeep(winsound.MB_ICONHAND)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "02a9a5160241461c95b6d7a3e60616ea": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "08ae3f9ebc9d4028963b364be8aa0a06": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "0d6923420edf421ba0bf8ae4bbfd15bc": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "0d69b6a279584428976ecf52050724e8": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "11e0a7c96146435191f3d8df8865ff0b": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "12f3da60161c487cadc9c4b12858becb": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "27e3939ab8184601be5e557b14e7e72a": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "2ad9bf02eccd46399ce5af32fb4815e8": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "2f63016615754f6b88d3b4c2143e8f18": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "32eb9dabe2ac4cb79f3a57cdbb7507b1": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "37b46cdb9f804a4f8d6528e380530d74": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "3fb82c9ea0b24cbf9a2e48cca604d934": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "48848ca18bd44a3ba517846aea503c54": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "58910c78e39446cbbbf0c16ce014a9d5": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "5d053fae72224070bece4b9890a7ae29": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "646bebeea21b4772b458f2a75c188292": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "660f77ff4e5f4b868d82d68795ad535b": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "6d658ea97b8d42dba04389a4e92740e6": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "6dffec1fddc944319a454cb71d36ce8f": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "7ba3ac9708b9470da043c860db892f42": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "83f80abec14a4e748ac519576e469afa": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "90e8ec893d8941d4805336ba72102903": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "9284085b404244f5981a77f8b9dc5ff7": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "96e177eb5b664a69af0bfc631c402c5c": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "98131e51f72e4284b7f43196bb00eda1": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "9b952b12a8794533aeb38c1cae6f63ba": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "9df2b3ad82b64ef5ab7215a35d2c28de": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "a69a0e74d5e640688f91afbbea1ed38c": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "a8578f68e3d846078a5756242d7db9d8": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "ad0f3828883345e08f15f8a234b2c4c3": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "ba8544a2480c43f3a17137adc1d1a052": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "bd83b5c1199e45b284dbafd39f857140": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "bda9ca6ba80b418d873c6315049b8633": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "c68dd0b38b4842ca84cc564885249ec5": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "c861cbd255ac4b3aa95c8f5a57d44634": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "c9181d57d9a44369b7f481007c0ce143": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "d185c046218a43659fd787e61eae1e3f": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "d3b10f2112744e6dbbd9ba0694a6d092": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "d5f7aeee5f2b4cfda0be9cf4c6a9e472": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "d8c9eaaffa60492794eb7b888c3dcbdb": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "e20553aafbd44441b28c8740a3ec5617": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "e26da7f008ef46e1ba54637982cd3730": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "efca7450bd364c2ea4d2aad41b0a2686": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f4864cca5a3c4780a74a571f9b82f50e": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    },
    "f793b3c13bc04c43a371684aaf0cc247": {
     "views": [
      {
       "cell_index": 7
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
