{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating unicity for 4 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation and pickling of `results` and `data_by_point` dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from dict_tools import *\n",
    "import pickle #For saving dictionaries with results\n",
    "import time #For calculating timings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FUNCTIONS\n",
    "def coarsen_time(timestamp,degree):\n",
    "    '''Coarsen time by the degree `degree`.\n",
    "    Degree is either 'd' (day), 'm' (minute), 'h' (hour), 's' (second), or False (exclude)\n",
    "    '''\n",
    "    if degree == 'd':\n",
    "        return timestamp[0:10]\n",
    "    elif degree == 'h':\n",
    "        return timestamp[0:13]\n",
    "    elif degree == 'm':\n",
    "        return timestamp[0:16]\n",
    "    elif degree == 's':\n",
    "        return timestamp[0:19]\n",
    "    else:\n",
    "        return None\n",
    "        \n",
    "unknown_curr = set()\n",
    "def coarsen_amount(amount,degree,currency):\n",
    "    '''Coarsen amount by the degree `degree`, which depends on the strength of\\\n",
    "        the `currency`. \n",
    "        `degree` can take:\n",
    "        'm'\" max, 'h': High, 'm': Medium, 'l': low\n",
    "        \n",
    "        Note that strength is not checked online, so it may not\\\n",
    "        be accurate if the strength of a currency has changed dramatically\n",
    "        \n",
    "        Note that rounding may not be perfect owing to floating point issues\n",
    "    '''\n",
    "    #Strength of currencies in 2014, I'm going to check these (I think XRP is \\\n",
    "    # now about as strong as the pound)\n",
    "    \n",
    "    strong_curr = ('BTC', 'XAG','XAU', 'XPT')\n",
    "    med_curr = ('CNY','EUR','USD','AUD','GBP','JPY') #<- STRENGTH OF XRP HAS CHANGED SINCE 2015\n",
    "    weak_curr = ('CCK','STR','KRW','MTL','XRP')\n",
    "    \n",
    "    lookup_strong = {'h': 1e-3, 'a': 1e-2, 'l': 1e-1}\n",
    "    lookup_med = {'h': 1e1, 'a': 1e2, 'l': 1e3}\n",
    "    lookup_weak = {'h': 1e5, 'a': 1e6, 'l': 1e7}\n",
    "    if degree is False:\n",
    "        return None\n",
    "    elif degree == 'm':\n",
    "        return amount\n",
    "    else:\n",
    "        if currency in strong_curr:\n",
    "            prec = lookup_strong[degree]\n",
    "        elif currency in med_curr:\n",
    "            prec = lookup_med[degree]\n",
    "        elif currency in weak_curr:\n",
    "            prec = lookup_weak[degree]\n",
    "        else:\n",
    "            unknown_curr.add(currency)\n",
    "            #print(\"Unknown currency {}\".format(currency))\n",
    "            prec = 1\n",
    "    \n",
    "        coarse_amount = float(int(round(amount/prec)))*prec\n",
    "\n",
    "        return coarse_amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#LOAD DATA\n",
    "start_date = datetime.date(2017,6,1)\n",
    "end_date = datetime.date(2017,8,29)\n",
    "date_list = pd.date_range(start_date,end_date,freq=\"1D\")\n",
    "\n",
    "files = []\n",
    "for day in date_list:\n",
    "    #print(\"Current date: {}\".format(day.strftime(\"%Y-%m-%d\")))\n",
    "    this_day = day.strftime(\"%Y-%m-%d\")\n",
    "    next_day = (day+datetime.timedelta(days=1)).strftime(\"%Y-%m-%d\")\n",
    "    files.append(\"Ripple_transactions_{}_to_{}.csv\".format(this_day,next_day))\n",
    "\n",
    "def load_data_by_sender(files,a_res,include_c,t_res,include_d):\n",
    "    '''Create dictionary from a list of file names `file` \\\n",
    "        with keys being senders and datapoints by tuple \\\n",
    "        (Amount, Currency, Time, Destination)'''\n",
    "    data_by_sender = {}\n",
    "    for file in tqdm(files):\n",
    "        i = 0\n",
    "        for line in csv.reader(open(file,'r')):\n",
    "            if i == 0:\n",
    "                header = line\n",
    "            else:\n",
    "                sender = line[header.index('Sender')]\n",
    "                \n",
    "                \n",
    "                curr = line[header.index('Currency')]\n",
    "                amount = coarsen_amount(float(line[header.index('Amount')]),a_res,curr)   #<- COARSENING \n",
    "                time = coarsen_time(line[header.index('Timestamp')],t_res)       #<- COARSENING\n",
    "                if include_d:\n",
    "                    destination = line[header.index('Destination')]\n",
    "                else:\n",
    "                    destination = None\n",
    "                if not include_c:\n",
    "                    curr = None\n",
    "                datapoint = tuple([amount,curr,time,destination])\n",
    "                \n",
    "                if sender not in data_by_sender:\n",
    "                    data_by_sender[sender] = set() \n",
    "                data_by_sender[sender].add(tuple(datapoint))\n",
    "            i+=1\n",
    "    return data_by_sender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def by_point(data_by_sender):\n",
    "    \"\"\"\n",
    "    Returns a dictionary mapping datapoints (Amount, Currency, Time, Destination) to the \\\n",
    "    users who share this datapoint\n",
    "    \n",
    "    \"\"\"\n",
    "    print(\"CONVERTING DATA BY SENDER TO DATA BY POINT\")\n",
    "    \n",
    "    data_by_point = {}\n",
    "    for sender in tqdm(data_by_sender):\n",
    "        for datapoint in data_by_sender[sender]:\n",
    "            if datapoint not in data_by_point:\n",
    "                data_by_point[datapoint] = set()\n",
    "            data_by_point[datapoint].add(sender)\n",
    "    \n",
    "    return data_by_point\n",
    "\n",
    "def get_unicity(dataset,p,npeople = 10000):\n",
    "    \"\"\"\n",
    "    Returns unicity (float) of `dataset` (dict), where `p` (int) is number of points sampled for each \\\n",
    "     person (if they have that many points) and `npeople` (int) is the number of people for whom their \\\n",
    "     uniqueness (for a set of points) is calculated\n",
    "    \"\"\"\n",
    "    if npeople == 'all':\n",
    "        npeople = len(dataset.keys())\n",
    "    else:\n",
    "        npeople = int(npeople) #Just to make sure\n",
    "    \n",
    "    points_to_users = by_point(dataset)\n",
    "    \n",
    "    print(\"User number: \",len(dataset))\n",
    "    print(\"Point number: \",len(points_to_users))\n",
    "\n",
    "    unique_users = set()\n",
    "    users = random.sample(list(dataset.keys()),npeople)\n",
    "    \n",
    "    users_included = set() #<- Users with at least p points\n",
    "\n",
    "    for u in tqdm(users):\n",
    "\n",
    "        u_data = dataset[u]\n",
    "\n",
    "        if len(u_data) < p: # <- NOT len(u_data) <= p\n",
    "            continue\n",
    "        else:\n",
    "            p_points = random.sample(u_data,p)\n",
    "            users_included.add(u)\n",
    "        is_unique = True\n",
    "        \n",
    "        similar_people = set(dataset.keys())\n",
    "\n",
    "        for point in p_points:\n",
    "            similar_people = similar_people.intersection(points_to_users[point])\n",
    "   \n",
    "\n",
    "        if len(similar_people) > 1:\n",
    "            is_unique = False\n",
    "            continue #<-NEED TO CONTINUE NOT BREAK!\n",
    "        \n",
    "        if is_unique:\n",
    "            unique_users.add(u) \n",
    "\n",
    "    print(\"Users included:\",len(users_included))\n",
    "    return len(unique_users)/len(users_included) #<-COMPARING WITH NUMBER OF USERS WITH AT LEAST p POINTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "experiments = {\"Am,Tsc,C,D\":['m',True,'s',True],\n",
    "               \"Am,Tsc,-,D\":['m',False,'s',True],\n",
    "               \"Am,Tsc,C,-\":['m',True,'s',False],\n",
    "               \"-,Tsc,C,D\": [False,True,'s',True],\n",
    "               \"Ah,Tmn,C,D\":['h',True,'m',True],\n",
    "               \"Aa,Thr,C,D\":['a',True,'h',True],\n",
    "               \"Al,Tdy,C,D\":['l',True,'d',True],\n",
    "               \"Am,-,C,D\":['m',True,False,True],\n",
    "               \"Am,-,-,-\":['m',False,False,False],\n",
    "               \"Al,Tdy,-,-\":['l',False,'d',False]\n",
    "              }\n",
    "experiments_test = {\"Am,Tsc,C,D\":['m',True,'s',True],\n",
    "               \"Am,Tsc,C,-\":['m',True,'s',False],\n",
    "               \"-,Tsc,C,D\":[False,True,'s',True],\n",
    "               }\n",
    "def run_experiment(parameters,p,name=\"unnamed_ripple_experiment\",npeople=10000):\n",
    "    '''Run experiment using resolutions defined in `parameters` \\\n",
    "        (Amount res, Include Currency, Time res, Include Destination)\n",
    "        and picking p datapoints for the unicity test\n",
    "        \n",
    "        Pickles the coarsened dataset object to a file {NAME}_p{P VALUE}-data_by_sender.pkl\n",
    "        '''\n",
    "    print(\"LOADING DATA\")\n",
    "    data_by_sender = load_data_by_sender(files,*parameters)\n",
    "    filename = '{}_p{}-data_by_sender.pkl'.format(name,p)\n",
    "    print(\"PICKLING DATA to {}\".format(filename))\n",
    "    pickle.dump(data_by_sender,open(filename,'wb'))\n",
    "    print(\"CALCULATING UNICITY\")\n",
    "    unicity = get_unicity(data_by_sender,p,npeople)\n",
    "    return unicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment Am,Tsc,C,D: Resolutions: ['m', True, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2310577\n",
      "\n",
      "Users included: 3045\n",
      "Experiment Am,Tsc,C,-: Resolutions: ['m', True, 's', False]\n",
      "LOADING DATA\n",
      "\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2216491\n",
      "\n",
      "Users included: 3097\n",
      "Experiment -,Tsc,C,D: Resolutions: [False, True, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2219769\n",
      "\n",
      "Users included: 3069\n"
     ]
    }
   ],
   "source": [
    "#Run on a subset of the experiments to check the code is working\n",
    "results_p1_test = {}\n",
    "for exp in experiments_test:\n",
    "    print(\"-------------------------------------------\\n\n",
    "    EXPERIMENT {}: COARSENING: {}\".format(exp,experiments_test[exp]))\n",
    "    results_p1_test[exp] = run_experiment(experiments_test[exp],p=4,name=exp,npeople=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-,Tsc,C,D': 0.9977191267513849, 'Am,Tsc,C,-': 1.0, 'Am,Tsc,C,D': 1.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_p1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------\n",
      "EXPERIMENT Am,Tsc,C,D: COARSENING: ['m', True, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,Tsc,C,D_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "89148/|/100%|| 89148/89148 [00:19<00:00, 4474.82it/s]                                                                  \n",
      "User number:  89148\n",
      "Point number:  2310577\n",
      "\n",
      "Users included: 3030\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,Tsc,-,D: COARSENING: ['m', False, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,Tsc,-,D_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2310571\n",
      "\n",
      "Users included: 3063\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,Tsc,C,-: COARSENING: ['m', True, 's', False]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,Tsc,C,-_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2216491\n",
      "\n",
      "Users included: 3073\n",
      "-------------------------------------------\n",
      "EXPERIMENT -,Tsc,C,D: COARSENING: [False, True, 's', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to -,Tsc,C,D_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2219769\n",
      "\n",
      "Users included: 3065\n",
      "-------------------------------------------\n",
      "EXPERIMENT Ah,Tmn,C,D: COARSENING: ['h', True, 'm', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Ah,Tmn,C,D_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  2047914\n",
      "\n",
      "Users included: 3005\n",
      "-------------------------------------------\n",
      "EXPERIMENT Aa,Thr,C,D: COARSENING: ['a', True, 'h', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Aa,Thr,C,D_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  1646653\n",
      "\n",
      "Users included: 2784\n",
      "-------------------------------------------\n",
      "EXPERIMENT Al,Tdy,C,D: COARSENING: ['l', True, 'd', True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Al,Tdy,C,D_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  931636\n",
      "\n",
      "Users included: 2387\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,-,C,D: COARSENING: ['m', True, False, True]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,-,C,D_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  770124\n",
      "\n",
      "Users included: 2868\n",
      "-------------------------------------------\n",
      "EXPERIMENT Am,-,-,-: COARSENING: ['m', False, False, False]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Am,-,-,-_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  479794\n",
      "\n",
      "Users included: 2752\n",
      "-------------------------------------------\n",
      "EXPERIMENT Al,Tdy,-,-: COARSENING: ['l', False, 'd', False]\n",
      "LOADING DATA\n",
      "\n",
      "PICKLING DATA to Al,Tdy,-,-_p4-data_by_sender.pkl\n",
      "CALCULATING UNICITY\n",
      "CONVERTING DATA BY SENDER TO DATA BY POINT\n",
      "\n",
      "User number:  89148\n",
      "Point number:  181818\n",
      "\n",
      "Users included: 2355\n"
     ]
    }
   ],
   "source": [
    "results_p4 = dict()\n",
    "for exp in experiments:\n",
    "    print(\"-------------------------------------------\\nEXPERIMENT {}: COARSENING: {}\".format(exp,experiments[exp]))\n",
    "    results_p4[exp] = run_experiment(experiments[exp],p=4,name=exp,npeople=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pickle.dump(results_p4,open('results_p4.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'-,Tsc,C,D': 0.9970636215334421,\n",
       " 'Aa,Thr,C,D': 0.9985632183908046,\n",
       " 'Ah,Tmn,C,D': 0.9993344425956738,\n",
       " 'Al,Tdy,-,-': 0.4900212314225053,\n",
       " 'Al,Tdy,C,D': 0.9639715123586091,\n",
       " 'Am,-,-,-': 0.6907703488372093,\n",
       " 'Am,-,C,D': 0.9532775453277545,\n",
       " 'Am,Tsc,-,D': 1.0,\n",
       " 'Am,Tsc,C,-': 1.0,\n",
       " 'Am,Tsc,C,D': 1.0}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_p4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {
    "0622d4010c8e49ef873ee60ffed4f743": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "07838ea5f9674cccaa14eedf5c715bcb": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "0afb118b67af4dd492944dc7aedd8094": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "0f54881d34c348feb112ade94c0fcc72": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "131be70409604367a8a145c72979720f": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "1c4eafc43ccf4c208e1f9c618b1227d8": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "200517bae64f4695b4fa67d933370690": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "25e95c75240445dbb8d68632641e3d72": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "2be75b1b07d546d38f6fe38a419f925c": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "2f4ddb4deb1f49eea09835803ea6a1e7": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "3596b84139e24854b8fcabe934189e37": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "3eac51cabf9d4e62989897326ab71e30": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "3f2f249b5465430a9aad96ed152b31ed": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "52a48b5787704c1b9ac7b40826ea8140": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "53cdbeeb6c7048268a8753175fad142e": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "59a5fe0de0404e37acbaa65ab593aa63": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "5ab15b6cbaac402c970122bdc8858575": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "5c545231272e485b8af44c35c0545d79": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "5dfc9a7df2b349f280deb50862b0beef": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "5eb351ba563742619da25be8a16cbcb4": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "64804a427c644863bdd48b93c5d07041": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "7516695a2705427c87f2f89ce820dcf3": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "80016a79dcbe49dc952ae514afcb6cfd": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "8406cceba4a74ba58abdc3792eea7e50": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "96ac5b7618424e5587935b60f7e4f499": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "9d4bfc7c0e4c4ea4ac6480b220a20ad4": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "9fc9f5e03aca4652b8b0e265de1c42e9": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "a381ab4c2f2342f69172b229e444b74a": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "afa3e3c19f4c4299b8479ca14a972536": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "b9278c3820d146929e2be6acef9d278b": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "c557436474ee4dd091308d50c7a86603": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "c87a170ed5fa480e9b570554be021cb8": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "df53e5268da74436ae06354dc240d3a3": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    },
    "e27518bff80d4761bc5bdd24f2bb566a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "e54f69df76b34647b87962a6ea7c9d9a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "effd35c5ba4b40bfbd2ba4c9f9bd778a": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "f0286cbf416d44498d7257b647b03e10": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "f0941b96a57f4c67a31fcb31f04a5835": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "f4e493a486cc40c995f7582832090cb8": {
     "views": [
      {
       "cell_index": 16
      }
     ]
    },
    "f72ce79b911e4608ac4d207bd7e8c299": {
     "views": [
      {
       "cell_index": 14
      }
     ]
    },
    "f9072ad9658d4a4687f851cdd476dbf1": {
     "views": [
      {
       "cell_index": 9
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
